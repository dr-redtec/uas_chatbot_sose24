{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m pdf_folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Extrahiere die Texte aus den PDFs\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_pdfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_folder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Beispielhafte Ausgabe des ersten Dokuments\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(documents[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeine Dokumente gefunden\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m, in \u001b[0;36mextract_text_from_pdfs\u001b[0;34m(pdf_folder_path)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_pdfs\u001b[39m(pdf_folder_path):\n\u001b[1;32m     46\u001b[0m     documents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_folder_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     50\u001b[0m             pdf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pdf_folder_path, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/pdf'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from collections import defaultdict\n",
    "\n",
    "def detect_columns(text_blocks, page_width):\n",
    "    \"\"\"Gruppiere Textblöcke basierend auf ihrer horizontalen Position (Spalten).\"\"\"\n",
    "    columns = defaultdict(list)\n",
    "    threshold = page_width * 0.15  # Threshold, um Spalten zu erkennen\n",
    "\n",
    "    for block in text_blocks:\n",
    "        x_center = (block['x0'] + block['x1']) / 2\n",
    "\n",
    "        assigned = False\n",
    "        for col_x in columns:\n",
    "            if abs(col_x - x_center) < threshold:\n",
    "                columns[col_x].append(block)\n",
    "                assigned = True\n",
    "                break\n",
    "        \n",
    "        if not assigned:\n",
    "            columns[x_center].append(block)\n",
    "\n",
    "    return columns\n",
    "\n",
    "def extract_text_from_column(column_blocks):\n",
    "    \"\"\"Sortiere die Blöcke innerhalb einer Spalte und extrahiere den Text.\"\"\"\n",
    "    sorted_blocks = sorted(column_blocks, key=lambda block: (block['top'], block['x0']))\n",
    "    return ' '.join([block['text'] for block in sorted_blocks])\n",
    "\n",
    "def extract_text_from_page(page):\n",
    "    \"\"\"Extrahiere den Text aus einer Seite, behalte dabei das Layout.\"\"\"\n",
    "    text_blocks = page.extract_words()\n",
    "    if not text_blocks:\n",
    "        return \"\"\n",
    "\n",
    "    columns = detect_columns(text_blocks, page.width)\n",
    "    full_text = []\n",
    "\n",
    "    for col_x, blocks in sorted(columns.items()):\n",
    "        column_text = extract_text_from_column(blocks)\n",
    "        full_text.append(column_text)\n",
    "\n",
    "    return \"\\n\\n\".join(full_text)\n",
    "\n",
    "def extract_text_from_pdfs(pdf_folder_path):\n",
    "    documents = []\n",
    "\n",
    "    for filename in os.listdir(pdf_folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_folder_path, filename)\n",
    "\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                full_text = []\n",
    "\n",
    "                for page in pdf.pages:\n",
    "                    page_text = extract_text_from_page(page)\n",
    "                    full_text.append(page_text)\n",
    "\n",
    "                documents.append(\"\\n\\n\".join(full_text))\n",
    "\n",
    "    return documents\n",
    "\n",
    "# Pfad zum PDF-Ordner\n",
    "pdf_folder_path = os.path.join('data', 'pdf')\n",
    "\n",
    "# Extrahiere die Texte aus den PDFs\n",
    "documents = extract_text_from_pdfs(pdf_folder_path)\n",
    "\n",
    "# Beispielhafte Ausgabe des ersten Dokuments\n",
    "print(documents[0] if documents else \"Keine Dokumente gefunden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "die Gelbe ausschließlich oder Glas sind. Nicht Verpackungen aus Zum Beispiel Altkleider Batterien und Akkus Behälterglas Blechgeschirr CDs und Disketten Druckerpatronen Einwegrasierer Elektrogeräte Essensreste Faltschachteln Feuerzeuge ilme, DVDs und Videokassetten Energiesparlampen Regionale Nähere Infos oder HIER Tonne den gebrauchte und restentleerte Verpackungen, Verpackungsbestandteile bitte voneinander Zum Beispiel -, Kunststoffdeckel Arzneimittelblister Butterfolie Joghurtbecher Einkaufstüten sowie Gemüsebeutel aus Kunststoff Eisverpackungen üllmaterial von verpackungen aus wie . . Luftpolsterfolie oder Schaumstoff Konservendosen Kronkorken für Lebensmittel die Gelbe Tonne den Papier, Pappe, Karton und Glas sowie Gummi Holzwolle Hygieneartikel Katzenstreu Keramikprodukte Kinderspielzeug Klarsichthüllen Kugelschreiber nicht restentleerte Papier und Pappe Papiertaschentücher Pflaster, Verbandsmaterial Porzellan Bioabfälle Ausnahmen sind möglich ( . . Wertstofftonne). erhältst bei deiner Kommune. klicken für deine zuständige Ansprechpartner . Gelben Sack die nicht aus trennen. Versand- Kunststoff, und Gelben sämtliche Abfälle, Verpackungen scannen gehören Papier, Pappe, Karton Ausspülen ist nicht notwendig. Menüschalen von Fertiggerichten Getränkekartons Müsliriegelfolie Nudeltüten Reinigungsmittelflaschen Nachfüllbeutel . . für Waschmittel, Flüssigseife oder Fruchtpüree Senftuben Shampooflaschen Spraydosen Soßentüten Tierfutterdosen Zahnpastatuben Sack gehören die keine Verpackungen Schuhe Strumpfhosen Styroporreste von Dämmplatten Tapetenreste Windeln Zahnbürsten Zigarettenkippen sind.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(documents):\n",
    "    \"\"\"Durchläuft die Liste der Dokumente und bereinigt die Texte.\"\"\"\n",
    "    cleaned_documents = []\n",
    "    \n",
    "    # Liste unerwünschter Zeichen oder Muster\n",
    "    unwanted_patterns = [\n",
    "        r\"\",     # Entferne das Symbol \n",
    "        r\"\",     # Beispiel für ein weiteres unerwünschtes Symbol\n",
    "        r\"(\\b\\w+\\s*-\\s*\\w+\\b)\",  # Entferne Worte mit unvollständigen Endungen (z.B. \"Glasfl aschen\")\n",
    "        r\"\\n+\",   # Entferne überflüssige Zeilenumbrüche\n",
    "        r\"\\s{2,}\",# Entferne überflüssige Leerzeichen\n",
    "        r\"\\s*:\\s*\",  # Entferne überflüssige Doppelpunkte\n",
    "        r\"\\b\\w{1,2}\\b\",  # Entferne isolierte kurze Wörter (z.B. \"fi\" in \"finden\")\n",
    "        r\"[^A-Za-z0-9äöüÄÖÜß.,;:!?()\\-'\\s]\"  # Entferne nicht-alphanumerische Zeichen\n",
    "    ]\n",
    "\n",
    "    # Regex-Muster kombinieren\n",
    "    combined_pattern = re.compile(\"|\".join(unwanted_patterns))\n",
    "\n",
    "    for document in documents:\n",
    "        # Entferne unerwünschte Zeichen und Muster\n",
    "        cleaned_text = combined_pattern.sub(\" \", document)\n",
    "        # Entferne mehrfach aufeinanderfolgende Leerzeichen, um den Text zu bereinigen\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "        cleaned_documents.append(cleaned_text)\n",
    "    \n",
    "    return cleaned_documents\n",
    "\n",
    "# Verwende die bestehende documents-Liste aus dem vorherigen Skript\n",
    "cleaned_documents = clean_text(documents)\n",
    "\n",
    "# Beispielhafte Ausgabe eines bereinigten Dokuments\n",
    "print(cleaned_documents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gelbe ausschließlich glas nicht verpackungen altkleider batterien akkus behälterglas blechgeschirr  disketten druckerpatronen einwegrasierer elektrogeräte essensreste faltschachteln feuerzeuge ilme dvds videokassetten energiesparlampen regionale nähere infos tonne gebrauchte restentleerte verpackungen verpackungsbestandteile bitte voneinander kunststoffdeckel arzneimittelblister butterfolie joghurtbecher einkaufstüten gemüsebeutel kunststoff eisverpackungen üllmaterial verpackungen luftpolsterfolie schaumstoff konservendosen kronkorken lebensmittel gelbe tonne papier pappe karton glas gummi holzwolle hygieneartikel katzenstreu keramikprodukte kinderspielzeug klarsichthüllen kugelschreiber nicht restentleerte papier pappe papiertaschentücher pflaster verbandsmaterial porzellan bioabfälle ausnahmen     wertstofftonne erhältst kommune klicken zuständige ansprechpartner gelben sack nicht trennen versand kunststoff gelben sämtliche abfälle verpackungen scannen gehören papier pappe karton ausspülen nicht notwendig menüschalen fertiggerichten getränkekartons müsliriegelfolie nudeltüten reinigungsmittelflaschen nachfüllbeutel waschmittel flüssigseife fruchtpüree senftuben shampooflaschen spraydosen soßentüten tierfutterdosen zahnpastatuben sack gehören verpackungen schuhe strumpfhosen styroporreste dämmplatten tapetenreste windeln zahnbürsten zigarettenkippen\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "# Lade das deutsche spaCy-Modell\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "def preprocess_text_with_advanced_cleaning(documents):\n",
    "    \"\"\"Bereinigt die Dokumente, entfernt unnötige Stopwörter und normalisiert den Text.\"\"\"\n",
    "    custom_stopwords = nlp.Defaults.stop_words.difference({'nicht', 'kein', 'wichtig'})\n",
    "\n",
    "    preprocessed_documents = []\n",
    "\n",
    "    for document in documents:\n",
    "        text = document.lower()\n",
    "        text = re.sub(r'\\b(?:[\\w\\-]+\\.)+[\\w]{2,4}(?:/[\\w\\-.?%&=]*)?\\b', '', text)\n",
    "        text = re.sub(r'\\b[\\w\\.\\-]+@[\\w\\.\\-]+\\.\\w{2,4}\\b', '', text)\n",
    "        text = re.sub(r'\\b(?:www|servicetelefon|servicetelefax|services|frankfurt|main|weidenbornstraße|liebfrauenberg)\\b', '', text)\n",
    "        text = re.sub(r'[^a-zäöüß\\s]', '', text)\n",
    "\n",
    "        doc = nlp(text)\n",
    "        filtered_tokens = [token.text for token in doc if token.text not in custom_stopwords and len(token.text) > 2]\n",
    "\n",
    "        # Entferne unzusammenhängende Zeichenfolgen und extrem kurze Wörter\n",
    "        text = ' '.join(filtered_tokens)\n",
    "        text = re.sub(r'\\b\\w{1,3}\\b', '', text)\n",
    "\n",
    "        # Entferne mehrfach aufeinanderfolgende gleiche Wörter\n",
    "        text = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', text)\n",
    "\n",
    "        # Entferne weiterhin sinnlose Textfragmente\n",
    "        text = re.sub(r'\\b[a-zäöüß]{2,3}\\b\\s+\\b[a-zäöüß]{2,3}\\b', '', text)\n",
    "\n",
    "        preprocessed_documents.append(text.strip())\n",
    "\n",
    "    return preprocessed_documents\n",
    "\n",
    "# Bereinige die Dokumente weiter\n",
    "preprocessed_documents = preprocess_text_with_advanced_cleaning(cleaned_documents)\n",
    "\n",
    "# Beispielhafte Ausgabe eines bereinigten Dokuments\n",
    "print(preprocessed_documents[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictiv_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
