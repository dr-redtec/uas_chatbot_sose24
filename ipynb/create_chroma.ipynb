{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Embeddings und Metadaten wurden erfolgreich aus 'data/pickle/embeddings_metadata.pkl' geladen.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_embeddings_and_metadata(filename=\"data/pickle/embeddings_metadata.pkl\"):\n",
    "    # Laden der Embeddings und Metadaten aus der Pickle-Datei\n",
    "    with open(filename, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    embeddings = data['embeddings']\n",
    "    metadatas = data['metadatas']\n",
    "    \n",
    "    print(f\"Die Embeddings und Metadaten wurden erfolgreich aus '{filename}' geladen.\")\n",
    "    return embeddings, metadatas\n",
    "\n",
    "# Beispielnutzung:\n",
    "embeddings, metadatas = load_embeddings_and_metadata(filename=\"data/pickle/embeddings_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0:\n",
      "\n",
      "Embedding: [ 0.19252267 -0.5782604  -0.19584805  0.02244737  0.38322002 -0.13617823\n",
      "  0.5281439  -0.08208066 -0.31730434  0.15474701]...\n",
      "Metadaten: {'text': 'batterien akkumulatoren gehören nicht brände auslösen umweltgefährdende stoffe enthalten mensch umwelt belasten ressourcen rohstoffe sammelboxen handel batterien verkauft supermärkte drogeriemärkte warenhäuser baumärkte tankstellen einpacktische kommunale sammelstellen wertstoffhöfe schadstoffmobile freiwillige sammelstellen unternehmen behörden hochschulen nicht batterien elektrogeräten entsorgung entnehmen batteriesammlung geben', 'keywords': ['wertstoffhof']}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Chunk 1:\n",
      "\n",
      "Embedding: [ 0.17300805 -0.2980221  -0.29367456  0.17560288  0.06461029 -0.10351696\n",
      "  0.5241277   0.19690768 -0.01365028  0.18295565]...\n",
      "Metadaten: {'text': 'gelbe tonne gelbe tonne gelber sack leeren verpackungen außer glas papier kunststoff metallen aluminium getränkebecher tipps verpackungen materialien trennen nicht stopfen recycelt deckel joghurtbecher kunststofftüten herausnehmen umwelt dankt', 'keywords': ['verpackung', 'glas', 'papier']}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Chunk 2:\n",
      "\n",
      "Embedding: [ 4.3404064e-01 -2.4971260e-01 -1.5038170e-01  2.2741932e-01\n",
      "  8.7421000e-02 -2.7009845e-04  3.4470347e-01  4.2496684e-01\n",
      " -2.6785630e-01  2.2231820e-01]...\n",
      "Metadaten: {'text': 'elektronikaltgeräte aufgrund hohen wertstoffgehaltes gesondert nicht entsorgen weist durchgestrichene mülltonne gerät wertstoffhöfe kommunale sammelstellen arten elektroaltgeräten sortiert container kleinere behälter rücknahme handel größere lebensmittelhändler elektrogeräte anbieten supermärkte discounter geschäfte elektrogeräte anbieten elektromärkte baumärkte elektroaltgeräte zurücknehmen kauf gleicher funktion geräte ohne kleinere händler nehmen elektroaltgeräte einheitliche kennzeichnungen rücknahmestellen elektrogeräten batterien', 'keywords': ['wertstoffhof']}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Chunk 3:\n",
      "\n",
      "Embedding: [ 0.2935095  -0.45509505 -0.27316836  0.24445032 -0.0947803  -0.04370401\n",
      "  0.49332154  0.25254503  0.06954183  0.18432726]...\n",
      "Metadaten: {'text': 'containersammlung leeren verpackungen glas farben sortiert flaschen ohne marmeladen senfgläser blaues glas bitte grünglas fall keramik glühbirnen kristallglas einwerfen stören', 'keywords': ['glas']}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Chunk 4:\n",
      "\n",
      "Embedding: [ 0.10822116 -0.29043102 -0.19471455 -0.15705377 -0.01447456 -0.2637631\n",
      " -0.02894411  0.35660025  0.0469551   0.10012254]...\n",
      "Metadaten: {'text': 'bioabfall biotonne organischen lebensmittelreste teebeutel kaffeesatz eierschalen gartenabfälle heckenschnitt plastiktüten verpackungen gefährden nutzung', 'keywords': ['verpackung']}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Anzahl der Einträge, die Du anzeigen möchtest\n",
    "num_examples = min(5, len(embeddings))  # Setzt num_examples auf 5 oder weniger, wenn nicht genug Embeddings vorhanden sind\n",
    "\n",
    "# Ausgabe der ersten paar Embeddings und ihrer zugehörigen Metadaten\n",
    "for i in range(num_examples):\n",
    "    print(f\"Chunk {i}:\\n\")\n",
    "    print(f\"Embedding: {embeddings[i][:10]}...\")  # Zeigt nur die ersten 10 Werte des Embeddings\n",
    "    print(f\"Metadaten: {metadatas[i]}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_embeddings_and_metadata(embeddings, metadatas, num_examples=5):\n",
    "    # Anzahl der Einträge, die Du anzeigen möchtest, begrenzen\n",
    "    num_examples = min(num_examples, len(embeddings))  # Setzt num_examples auf 5 oder weniger, wenn nicht genug Embeddings vorhanden sind\n",
    "    \n",
    "    # Ausgabe der Embeddings und ihrer zugehörigen Metadaten\n",
    "    for i in range(num_examples):\n",
    "        print(f\"Chunk {i}:\\n\")\n",
    "        print(f\"Embedding: {embeddings[i][:10]}...\")  # Zeigt nur die ersten 10 Werte des Embeddings\n",
    "        print(f\"Metadaten: {metadatas[i]}\")\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Beispielnutzung:\n",
    "display_embeddings_and_metadata(embeddings, metadatas, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "def delete_chroma_collection(collection_name='document_embeddings_v2'):\n",
    "    # Erstelle oder öffne eine Chroma-Datenbank\n",
    "    client = chromadb.Client()\n",
    "\n",
    "    # Prüfe, ob die Collection existiert\n",
    "    if collection_name in [c.name for c in client.list_collections()]:\n",
    "        # Lösche die Collection\n",
    "        client.delete_collection(collection_name)\n",
    "        print(f\"Collection '{collection_name}' erfolgreich gelöscht.\")\n",
    "    else:\n",
    "        print(f\"Collection '{collection_name}' existiert nicht.\")\n",
    "\n",
    "# Beispielnutzung:\n",
    "delete_chroma_collection(collection_name='document_embeddings_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "def create_chroma_database_v2(embeddings, metadatas, collection_name='document_embeddings_v2'):\n",
    "    # Erstelle oder öffne eine Chroma-Datenbank\n",
    "    client = chromadb.Client()\n",
    "    \n",
    "    # Erstelle eine neue Collection in der Datenbank mit einem anderen Namen\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "    \n",
    "    # Konvertiere Embeddings von numpy array in Liste von Listen\n",
    "    embeddings_as_list = [embedding.tolist() for embedding in embeddings]\n",
    "    \n",
    "    # Füge die Embeddings und Metadaten zur Collection hinzu\n",
    "    for i, (embedding, metadata) in enumerate(zip(embeddings_as_list, metadatas)):\n",
    "        # Metadaten umwandeln, sodass die Liste der Keywords als String gespeichert wird\n",
    "        metadata['keywords'] = ','.join(metadata['keywords'])\n",
    "        \n",
    "        collection.add(\n",
    "            embeddings=[embedding],\n",
    "            metadatas=[metadata],\n",
    "            ids=[f\"doc_{i}\"]\n",
    "        )\n",
    "    \n",
    "    print(f\"Chroma-Datenbank '{collection_name}' erfolgreich erstellt und {len(embeddings)} Embeddings hinzugefügt.\")\n",
    "\n",
    "# Beispielnutzung:\n",
    "create_chroma_database_v2(embeddings, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def query_chroma_database(query_text, collection_name='document_embeddings_v2', top_k=5, model_name='sentence-transformers/multi-qa-mpnet-base-dot-v1'):\n",
    "    # Lade das vortrainierte Modell\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Erstelle oder öffne eine Chroma-Datenbank\n",
    "    client = chromadb.Client()\n",
    "\n",
    "    # Öffne die Collection\n",
    "    collection = client.get_collection(name=collection_name)\n",
    "\n",
    "    # Erstelle ein Embedding für die Abfrage\n",
    "    query_embedding = model.encode(query_text).tolist()\n",
    "\n",
    "    # Suche in der Collection nach den besten Übereinstimmungen\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Beispielnutzung:\n",
    "query_text = \"Wie entsorge ich Altglas in Frankfurt?\"\n",
    "results = query_chroma_database(query_text)\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "for i, (doc_id, metadata) in enumerate(zip(results['ids'], results['metadatas'])):\n",
    "    print(f\"Ergebnis {i+1}:\")\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(f\"Metadaten: {metadata}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_v2(chroma_client, query, keywords, embedding_model, collection_name=\"document_embeddings_v2\", top_k=10):\n",
    "    # 1. Semantische Suche: Finde ähnliche Dokumente basierend auf dem Query-Embedding\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "    semantic_results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # 2. Klassische Textsuche: Finde exakte Übereinstimmungen für Keywords\n",
    "    text_search_results = []\n",
    "    for i in range(len(semantic_results['ids'][0])):\n",
    "        metadata = semantic_results['metadatas'][0][i]\n",
    "        if isinstance(metadata, dict) and any(keyword.lower() in metadata['text'].lower() for keyword in keywords):\n",
    "            text_search_results.append({\n",
    "                'id': semantic_results['ids'][0][i],\n",
    "                'text': metadata['text'],\n",
    "                'score': 1.0  # Hohe Gewichtung für exakte Übereinstimmung\n",
    "            })\n",
    "    \n",
    "    # 3. Kombination der Ergebnisse: Füge Gewichtung basierend auf der Suchmethode hinzu\n",
    "    combined_results = []\n",
    "    for i in range(len(semantic_results['ids'][0])):\n",
    "        # Hole den einzelnen Distanzwert\n",
    "        distance = float(semantic_results['distances'][0][i])\n",
    "        combined_score = 0.6 * (1 - distance)  # Angepasste Gewichtung für semantische Suche\n",
    "        combined_results.append({\n",
    "            'id': semantic_results['ids'][0][i],\n",
    "            'text': semantic_results['metadatas'][0][i]['text'] if isinstance(semantic_results['metadatas'][0][i], dict) else \"\",\n",
    "            'score': combined_score\n",
    "        })\n",
    "    \n",
    "    combined_results.extend(text_search_results)\n",
    "    \n",
    "    # 4. Sortieren der kombinierten Ergebnisse nach Score (höchste zuerst)\n",
    "    combined_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # 5. Ausgabe der Top-k Ergebnisse\n",
    "    return combined_results[:top_k]\n",
    "\n",
    "# Beispielnutzung:\n",
    "query = \"Wie entsorge ich Altglas in Frankfurt?\"\n",
    "keywords = [\"altglascontainer\", \"restmüll\", \"wertstoffhof\"]\n",
    "hybrid_results_v2 = hybrid_search_v2(chroma_client, query, keywords, embedding_model)\n",
    "\n",
    "# Ausgabe der hybriden Suchergebnisse\n",
    "for i, result in enumerate(hybrid_results_v2):\n",
    "    print(f\"Ergebnis {i+1}:\\n\")\n",
    "    print(f\"ID: {result['id']}\")\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Lade das deutsche Sprachmodell von spaCy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def extract_keywords_from_query(query, custom_stopwords=None):\n",
    "    \"\"\"\n",
    "    Extrahiert Keywords aus einer Query durch Tokenisierung und Entfernung von Stoppwörtern.\n",
    "    \"\"\"\n",
    "    if custom_stopwords is None:\n",
    "        custom_stopwords = set(nlp.Defaults.stop_words)\n",
    "    \n",
    "    # Tokenisiere die Query\n",
    "    doc = nlp(query.lower())\n",
    "    \n",
    "    # Extrahiere Keywords: Wörter, die keine Stoppwörter, Zahlen oder Satzzeichen sind\n",
    "    keywords = [token.text for token in doc if token.text not in custom_stopwords and not token.is_punct and not token.like_num]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Beispielnutzung:\n",
    "query2 = \"Wie entsorge ich Altglas in Frankfurt?\"\n",
    "keywords2 = extract_keywords_from_query(query2)\n",
    "\n",
    "# test chroma\n",
    "\n",
    "#hybrid_results_v21 = hybrid_search_v2(chroma_client, query2, keywords2, embedding_model)\n",
    "\n",
    "#print(f\"Query: {query2}\")\n",
    "#print(f\"Extrahierte Keywords: {keywords2}\")\n",
    "# Ausgabe der hybriden Suchergebnisse\n",
    "#for i, result in enumerate(hybrid_results_v21):\n",
    "#    print(f\"Ergebnis {i+1}:\\n\")\n",
    " #   print(f\"ID: {result['id']}\")\n",
    "  #  print(f\"Text: {result['text']}\")\n",
    "   # print(f\"Score: {result['score']}\")\n",
    "    #print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplizierung und kombinierte Gewichtung verbessern\n",
    "def hybrid_search_v3(chroma_client, query, keywords, embedding_model, collection_name=\"document_embeddings_v2\", top_k=10):\n",
    "    # 1. Semantische Suche\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "    semantic_results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # 2. Klassische Textsuche\n",
    "    text_search_results = []\n",
    "    for i in range(len(semantic_results['ids'][0])):\n",
    "        metadata = semantic_results['metadatas'][0][i]\n",
    "        if isinstance(metadata, dict) and any(keyword.lower() in metadata['text'].lower() for keyword in keywords):\n",
    "            text_search_results.append({\n",
    "                'id': semantic_results['ids'][0][i],\n",
    "                'text': metadata['text'],\n",
    "                'keywords': keywords,\n",
    "                'score': 1.0  # Hohe Gewichtung für exakte Übereinstimmung\n",
    "            })\n",
    "    \n",
    "    # 3. Kombination der Ergebnisse\n",
    "    combined_results = []\n",
    "    seen_ids = set()  # Set zur Deduplizierung\n",
    "    for i in range(len(semantic_results['ids'][0])):\n",
    "        distance = float(semantic_results['distances'][0][i])\n",
    "        combined_score = 0.6 * (1 - distance)  # Angepasste Gewichtung für semantische Suche\n",
    "        \n",
    "        if semantic_results['ids'][0][i] not in seen_ids:\n",
    "            seen_ids.add(semantic_results['ids'][0][i])\n",
    "            combined_results.append({\n",
    "                'id': semantic_results['ids'][0][i],\n",
    "                'text': semantic_results['metadatas'][0][i]['text'] if isinstance(semantic_results['metadatas'][0][i], dict) else \"\",\n",
    "                'keywords': keywords,\n",
    "                'score': combined_score\n",
    "            })\n",
    "    \n",
    "    for result in text_search_results:\n",
    "        if result['id'] not in seen_ids:\n",
    "            combined_results.append(result)\n",
    "    \n",
    "    # 4. Sortieren der kombinierten Ergebnisse nach Score\n",
    "    combined_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # 5. Normierung der Scores (falls nötig)\n",
    "    min_score = min([r['score'] for r in combined_results])\n",
    "    if min_score < 0:\n",
    "        for result in combined_results:\n",
    "            result['score'] += abs(min_score)\n",
    "    \n",
    "    # 6. Ausgabe der Top-k Ergebnisse\n",
    "    return combined_results[:top_k]\n",
    "\n",
    "# Beispielnutzung:\n",
    "query4 = \"Wie entsorge ich Altglas in Frankfurt?\"\n",
    "keywords4 = extract_keywords_from_query(query4)\n",
    "\n",
    "hybrid_results_v3 = hybrid_search_v3(chroma_client, query4, keywords4, embedding_model)\n",
    "\n",
    "print(f\"Query: {query4}\")\n",
    "print(f\"Extrahierte Keywords: {keywords4}\")\n",
    "# Ausgabe der hybriden Suchergebnisse\n",
    "for i, result in enumerate(hybrid_results_v3):\n",
    "    print(f\"Ergebnis {i+1}:\\n\")\n",
    "    print(f\"ID: {result['id']}\")\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Keywords: {result.get('keywords', [])}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erweiterte Version der hybriden Suche mit normalisierter Distanzberechnung, Version 5\n",
    "def hybrid_search_v5(chroma_client, query, keywords, embedding_model, collection_name=\"document_embeddings_v2\", top_k=10):\n",
    "    # 1. Semantische Suche\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "    semantic_results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # 2. Distanznormalisierung\n",
    "    distances = semantic_results['distances'][0]\n",
    "    min_distance = min(distances)\n",
    "    max_distance = max(distances)\n",
    "    normalized_distances = [(d - min_distance) / (max_distance - min_distance) for d in distances]\n",
    "    \n",
    "    # 3. Klassische Textsuche basierend auf Keywords\n",
    "    text_search_results = []\n",
    "    for i in range(len(semantic_results['ids'][0])):\n",
    "        metadata = semantic_results['metadatas'][0][i]\n",
    "        keyword_count = sum(keyword.lower() in metadata['text'].lower() for keyword in keywords)\n",
    "        if keyword_count > 0:\n",
    "            text_search_results.append({\n",
    "                'id': semantic_results['ids'][0][i],\n",
    "                'text': metadata['text'],\n",
    "                'keywords': keywords,\n",
    "                'score': 1.0 + 0.5 * keyword_count  # Gewichtung für Keywords\n",
    "            })\n",
    "    \n",
    "    # 4. Kombination der Ergebnisse\n",
    "    combined_results = []\n",
    "    seen_ids = set()\n",
    "    for i in range(len(semantic_results['ids'][0])):\n",
    "        distance = normalized_distances[i]\n",
    "        combined_score = 1.0 - distance  # Gewichtung für semantische Suche\n",
    "        \n",
    "        if semantic_results['ids'][0][i] not in seen_ids:\n",
    "            seen_ids.add(semantic_results['ids'][0][i])\n",
    "            combined_results.append({\n",
    "                'id': semantic_results['ids'][0][i],\n",
    "                'text': semantic_results['metadatas'][0][i]['text'] if isinstance(semantic_results['metadatas'][0][i], dict) else \"\",\n",
    "                'keywords': keywords,\n",
    "                'score': combined_score\n",
    "            })\n",
    "    \n",
    "    for result in text_search_results:\n",
    "        if result['id'] not in seen_ids:\n",
    "            combined_results.append(result)\n",
    "    \n",
    "    # 5. Sortieren der kombinierten Ergebnisse nach Score\n",
    "    combined_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # 6. Ausgabe der Top-k Ergebnisse\n",
    "    return combined_results[:top_k]\n",
    "\n",
    "# Beispielnutzung:\n",
    "query5 = \"Wie entsorge ich Altglas in Frankfurt?\"\n",
    "keywords5 = extract_keywords_from_query(query5)\n",
    "\n",
    "# Durchführung der hybriden Suche mit Keywords\n",
    "hybrid_results_v5 = hybrid_search_v5(chroma_client, query5, keywords5, embedding_model)\n",
    "\n",
    "print(f\"Query: {query5}\")\n",
    "print(f\"Extrahierte Keywords: {keywords5}\")\n",
    "# Ausgabe der hybriden Suchergebnisse\n",
    "for i, result in enumerate(hybrid_results_v5):\n",
    "    print(f\"Ergebnis {i+1}:\\n\")\n",
    "    print(f\"ID: {result['id']}\")\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Keywords: {result.get('keywords', [])}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# Lade das vortrainierte Modell\n",
    "model_name = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Initialisiere den Chroma-Client\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Überprüfe, ob die Collection existiert\n",
    "def get_existing_collection(chroma_client, collection_name=\"document_embeddings_v2\"):\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(name=collection_name)\n",
    "        print(f\"Collection {collection_name} erfolgreich geladen.\")\n",
    "        return collection\n",
    "    except ValueError:\n",
    "        print(f\"Collection {collection_name} existiert nicht.\")\n",
    "        return None\n",
    "\n",
    "# Zugriff auf die bestehende Collection\n",
    "collection = get_existing_collection(chroma_client, \"document_embeddings_v2\")\n",
    "\n",
    "if collection is None:\n",
    "    print(\"Die angegebene Collection existiert nicht. Bitte überprüfe den Collection-Namen.\")\n",
    "else:\n",
    "    # Erweiterte Version der hybriden Suche mit normalisierter Distanzberechnung, Version 5\n",
    "    def hybrid_search_v5(chroma_client, query, keywords, embedding_model, collection_name=\"document_embeddings_v2\", top_k=10):\n",
    "        # 1. Semantische Suche\n",
    "        query_embedding = embedding_model.encode(query).tolist()\n",
    "        collection = chroma_client.get_collection(name=collection_name)\n",
    "        semantic_results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        # 2. Distanznormalisierung\n",
    "        distances = semantic_results['distances'][0]\n",
    "        min_distance = min(distances)\n",
    "        max_distance = max(distances)\n",
    "        normalized_distances = [(d - min_distance) / (max_distance - min_distance) for d in distances]\n",
    "        \n",
    "        # 3. Klassische Textsuche basierend auf Keywords\n",
    "        text_search_results = []\n",
    "        for i in range(len(semantic_results['ids'][0])):\n",
    "            metadata = semantic_results['metadatas'][0][i]\n",
    "            keyword_count = sum(keyword.lower() in metadata['text'].lower() for keyword in keywords)\n",
    "            if keyword_count > 0:\n",
    "                text_search_results.append({\n",
    "                    'id': semantic_results['ids'][0][i],\n",
    "                    'text': metadata['text'],\n",
    "                    'keywords': keywords,\n",
    "                    'score': 1.0 + 0.5 * keyword_count  # Gewichtung für Keywords\n",
    "                })\n",
    "        \n",
    "        # 4. Kombination der Ergebnisse\n",
    "        combined_results = []\n",
    "        seen_ids = set()\n",
    "        for i in range(len(semantic_results['ids'][0])):\n",
    "            distance = normalized_distances[i]\n",
    "            combined_score = 1.0 - distance  # Gewichtung für semantische Suche\n",
    "            \n",
    "            if semantic_results['ids'][0][i] not in seen_ids:\n",
    "                seen_ids.add(semantic_results['ids'][0][i])\n",
    "                combined_results.append({\n",
    "                    'id': semantic_results['ids'][0][i],\n",
    "                    'text': semantic_results['metadatas'][0][i]['text'] if isinstance(semantic_results['metadatas'][0][i], dict) else \"\",\n",
    "                    'keywords': keywords,\n",
    "                    'score': combined_score\n",
    "                })\n",
    "        \n",
    "        for result in text_search_results:\n",
    "            if result['id'] not in seen_ids:\n",
    "                combined_results.append(result)\n",
    "        \n",
    "        # 5. Sortieren der kombinierten Ergebnisse nach Score\n",
    "        combined_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        # 6. Ausgabe der Top-k Ergebnisse\n",
    "        return combined_results[:top_k]\n",
    "\n",
    "    # Beispielnutzung:\n",
    "    query5 = \"Wie entsorge ich Altglas in Frankfurt?\"\n",
    "    keywords5 = extract_keywords_from_query(query5)\n",
    "\n",
    "    # Durchführung der hybriden Suche mit Keywords\n",
    "    hybrid_results_v5 = hybrid_search_v5(chroma_client, query5, keywords5, embedding_model)\n",
    "\n",
    "    print(f\"Query: {query5}\")\n",
    "    print(f\"Extrahierte Keywords: {keywords5}\")\n",
    "    # Ausgabe der hybriden Suchergebnisse\n",
    "    for i, result in enumerate(hybrid_results_v5):\n",
    "        print(f\"Ergebnis {i+1}:\\n\")\n",
    "        print(f\"ID: {result['id']}\")\n",
    "        print(f\"Text: {result['text']}\")\n",
    "        print(f\"Keywords: {result.get('keywords', [])}\")\n",
    "        print(f\"Score: {result['score']}\")\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma-Datenbank 'document_embeddings_v2' erfolgreich erstellt und 8 Embeddings hinzugefügt.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "\n",
    "def create_chroma_database_v2(embeddings, metadatas, collection_name='document_embeddings_v2', persist_directory='chroma_db'):\n",
    "    # Erstelle oder öffne eine Chroma-Datenbank mit Persistierung\n",
    "    client = chromadb.PersistentClient(\n",
    "        path=persist_directory,\n",
    "        settings=Settings(),\n",
    "        tenant=DEFAULT_TENANT,\n",
    "        database=DEFAULT_DATABASE,\n",
    "    )\n",
    "    \n",
    "    # Erstelle eine neue Collection in der Datenbank oder lade eine bestehende\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "    \n",
    "    # Konvertiere Embeddings von numpy array in Liste von Listen\n",
    "    embeddings_as_list = [embedding.tolist() for embedding in embeddings]\n",
    "    \n",
    "    # Füge die Embeddings und Metadaten zur Collection hinzu\n",
    "    for i, (embedding, metadata) in enumerate(zip(embeddings_as_list, metadatas)):\n",
    "        # Metadaten umwandeln, sodass die Liste der Keywords als String gespeichert wird\n",
    "        metadata['keywords'] = ','.join(metadata['keywords'])\n",
    "        \n",
    "        collection.add(\n",
    "            embeddings=[embedding],\n",
    "            metadatas=[metadata],\n",
    "            ids=[f\"doc_{i}\"]\n",
    "        )\n",
    "    \n",
    "    print(f\"Chroma-Datenbank '{collection_name}' erfolgreich erstellt und {len(embeddings)} Embeddings hinzugefügt.\")\n",
    "\n",
    "# Beispielnutzung:\n",
    "create_chroma_database_v2(embeddings, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'document_embeddings_v2' erfolgreich gelöscht.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "\n",
    "def delete_chroma_collection(collection_name='document_embeddings_v2', persist_directory='chroma_db'):\n",
    "    # Öffne die Chroma-Datenbank mit Persistierung\n",
    "    client = chromadb.PersistentClient(\n",
    "        path=persist_directory,\n",
    "        settings=Settings(),\n",
    "        tenant=DEFAULT_TENANT,\n",
    "        database=DEFAULT_DATABASE,\n",
    "    )\n",
    "    \n",
    "    # Überprüfe, ob die Collection existiert, und lösche sie, wenn ja\n",
    "    existing_collections = [col.name for col in client.list_collections()]\n",
    "    if collection_name in existing_collections:\n",
    "        client.delete_collection(name=collection_name)\n",
    "        print(f\"Collection '{collection_name}' erfolgreich gelöscht.\")\n",
    "    else:\n",
    "        print(f\"Collection '{collection_name}' nicht gefunden.\")\n",
    "        \n",
    "delete_chroma_collection(collection_name='document_embeddings_v2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictiv_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
